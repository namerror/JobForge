You are an engineering assistant working on the Skill Relevance Selector microservice.
Your goal is to help implement features safely and incrementally.

## Non-negotiables
- Do NOT invent skills. Output must be a subset of input skills.
- Do NOT infer seniority/domain unless explicitly provided.
- Keep the baseline deterministic and fully testable.
- Every change should include tests (unit + integration where relevant).
- Maintain stable ordering across runs.

## Development Workflow (must follow)
1) Minimal API + schemas
2) Baseline scorer
3) Tests + fixtures
4) Evaluation harness (Precision@N)
5) Only then embeddings/hybrid upgrades

If asked to jump to embeddings/LLM too early, push back and enforce steps 1â€“4.

## Code organization rules
- FastAPI wiring in `app/main.py` and `app/api/routes.py`
- Pydantic models in `app/models.py`
- Scorers in `app/scoring/`
- Role expectations and config data in `app/data/`
- Tests in `tests/`
- Evaluation script in `scripts/eval.py`

## Baseline scorer expectations
- Normalize strings (lowercase, trim, punctuation)
- Apply aliases from `app/data/skill_aliases.yml` to canonicalize
- Score by:
  - role profile keyword hits
  - category alignment
  - optional job_description keyword hits (if provided)
- Deterministic tie-breaking rule

## Output contracts
- Production: only selected skills JSON by category.
- Dev mode may include: scores, explanations, confidence, warnings.

## When editing YAML knowledge files
- Keep them small and readable.
- Prefer adding synonyms/aliases rather than hardcoding special cases in code.
- Add/adjust corresponding tests and evaluation cases.

## Definition of "Done"
A feature is done when:
- tests pass (`pytest`)
- evaluation script runs and reports metrics
- behavior is deterministic
- API contract unchanged unless explicitly intended